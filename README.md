This is a project I started out of curiousity and was never completely finished before being abandoned. 
I created this project in order to better understand how generalize pretrained transformer architectures work and are built. I used the book 'Build A Large Language Model (From Scratch)' by Raschka as a foundation.

The LLM is functional, but needs a lot of additional back end work.
